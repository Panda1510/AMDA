{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modular "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been collected using the modular rig tester that shown in figure a. The tester consists of several components : (1) electric motor;(2) s torque-measurement shaft ;(3) a rolling bearing test module; (4) fly wheel;(5) load motor. A detailed explanation of the modular tester can be found [KAt].  \n",
    "![alt text](pics\KAt.png \"Modular Test Rig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, rolling bearing elements with about 32 bearing experiment has been conducted as shown: \n",
    "- 6 bearings are undamaged (heakthy)\n",
    "- 12 bearings with artificial damages- \n",
    "- 14 bearings with real accelerated damages. \n",
    "\n",
    "The artificial and real damages have two fault types: inner and outer ring faults.  20 measurements are conducted for each bearing file, each file collected under 64 KHz sampling rate and last for 4 seconds. Hence, the data file can have around 256000 data points.  The experiments carried out under 4 different working conditions.  Different parameters among working conditions such as: rotational speed, load torque, and radial force. Rotational speed varied between 900 rpm and 1500 rpm, while load toque changed from 0.1 Nm to 0.7 Nm, while the asserted radial force has been increased from 400N to 1000N. Table_x shows the set up of the 4 different operating conditions. \n",
    "\n",
    "Summary: \n",
    "- The dataset has 26 damaged bearing states (i.e., 12 artificial damages and 14 real damages) and 6 healthy(undamaged) bearing states.\n",
    "- Four different operating conditions. \n",
    "- 20 measurements of 4 second each for each bearing file, where each file name has code of to represent its operating working condition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading of 20 measurements for each real damage file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset we employed files with real damages damages for more practical scenario. the experiments conducted under 4 differnt working conditions. The following table shows the selected real files train our model for each wokring condition. Each of these files (e.g. KA01, KA02, KI01,....) has 20 measurements (e.g. KA01_1,.....,KA01_20). Signle measurement has 256000 data points (i.e. 64 KHz and 4 seconds long). To load these files automatically we implemented matalb code \"automatic file loading\". The output of matlab code will be (A_5120L, B5120L, C5120L, D_5120L)\n",
    "In our experiement we  used single healthy file,  5 files with outer faults, and 5 files with inner faults. \n",
    "\n",
    "![alt text](pics\\real_1.png \"Modular Test Rig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data augmentation using sliding window "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the lengthy data files with 2560000, we used sliding window to extract a short samples and applied overlapping to increase the number of samples. For each measurement we used window length of 5120 and shifiting size of 4096 as shown in the following figure. Note that for the healthy samples the shfting size reduced to 1024 to balance the number of healthy data. Finally we woll have 4900 healthy samples, 6200 inner faulty, and 6200 outer faulty samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"pics\\window_3.png\" alt=\"Drawing\" style=\"width: 900px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following equations show the details about calcuating number of generated samples:\n",
    "\n",
    "\\begin{align}\n",
    "   \\textbf{n}  & =ceil \\ (\\frac{T - L}{S}) * number\\_of \\_measuerements  \\\\ \\\\\n",
    "   \\textbf{N}&=\\textbf{n}* number\\_of\\_class\\_files \\\\ \\\\\n",
    "      \\textbf{K} &=\\textbf{N}* number\\_of\\_classes.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $n$ is number samples per file,$N$ is the number of samples for each class, and __K__ is the total number of samples for each working conditions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Constructing samples for different working conditions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct data and labels working condition A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files for realing data_a \n",
    "# health data_a\n",
    "K001=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['K001']))\n",
    "\n",
    "#outer Fault \n",
    "KA22=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KA22']))\n",
    "KA04=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KA04']))\n",
    "KA15=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KA15']))\n",
    "KA30=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KA30']))\n",
    "KA16=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KA16']))\n",
    "\n",
    "# #inner Fault\n",
    "KI16=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KI16']))\n",
    "KI17=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KI17']))\n",
    "KI18=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KI18']))\n",
    "KI21=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KI21']))\n",
    "KI14=torch.from_numpy(np.asarray(data_a['A_5120L']['real']['KI14']))\n",
    "\n",
    "# Constructing realing data_a and labels for working conition 0 \n",
    "real_data_a=torch.cat((K001,KA22,KA04,,KA15,KA30,KA16,KI14,KI21,KI17,KI18,KI16),dim=0)\n",
    "print(real_data_a.size())\n",
    "\n",
    "# Generating labels\n",
    "a=torch.LongTensor(K001.size(0)).fill_(0)\n",
    "b=torch.LongTensor(KA04.size(0)*5).fill_(1)\n",
    "c=torch.LongTensor(KA04.size(0)*5).fill_(2)\n",
    "real_labels_a=torch.cat((a,b,c),dim=0)\n",
    "print(real_labels_a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split  working condition A  into traininhg and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * (real_data_a[0].size(0)))\n",
    "test_size = real_data_a[0].size(0)- train_size\n",
    "inx=np.arange(real_data_a[0].size(0))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(inx, [train_size, test_size])\n",
    "\n",
    "train_data=real_data_a[0][train_dataset]\n",
    "train_labels=real_data_a[1][train_dataset]\n",
    "test_data=real_data_a[0][test_dataset].float()\n",
    "test_labels=real_data_a[1][test_dataset].long()\n",
    "\n",
    "domain_a=train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct data and labels working condition B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files for realing data_b \n",
    "# health data_b\n",
    "K001=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['K001']))\n",
    "\n",
    "#outer Fault \n",
    "KA22=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KA22']))\n",
    "KA04=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KA04']))\n",
    "KA15=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KA15']))\n",
    "KA30=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KA30']))\n",
    "KA16=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KA16']))\n",
    "\n",
    "# #inner Fault\n",
    "KI16=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KI16']))\n",
    "KI17=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KI17']))\n",
    "KI18=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KI18']))\n",
    "KI21=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KI21']))\n",
    "KI14=torch.from_numpy(np.asarray(data_b['B_5120L']['real']['KI14']))\n",
    "\n",
    "# Constructing realing data_b and labels for working conition 0 \n",
    "real_data_b=torch.cat((K001,KA22,KA04,,KA15,KA30,KA16,KI14,KI21,KI17,KI18,KI16),dim=0)\n",
    "print(real_data_b.size())\n",
    "\n",
    "# Generating labels\n",
    "a=torch.LongTensor(K001.size(0)).fill_(0)\n",
    "b=torch.LongTensor(KA04.size(0)*5).fill_(1)\n",
    "c=torch.LongTensor(KA04.size(0)*5).fill_(2)\n",
    "real_labels_b=torch.cat((a,b,c),dim=0)\n",
    "print(real_labels_b.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split  working condition B  into traininhg and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * (real_data_b[0].size(0)))\n",
    "test_size = real_data_b[0].size(0)- train_size\n",
    "inx=np.arange(real_data_b[0].size(0))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(inx, [train_size, test_size])\n",
    "\n",
    "train_data=real_data_b[0][train_dataset]\n",
    "train_labels=real_data_b[1][train_dataset]\n",
    "test_data=real_data_b[0][test_dataset].float()\n",
    "test_labels=real_data_b[1][test_dataset].long()\n",
    "\n",
    "domain_b=train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct data and labels working condition C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files for realing data_c \n",
    "# health data_c\n",
    "K001=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['K001']))\n",
    "\n",
    "#outer Fault \n",
    "KA22=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KA22']))\n",
    "KA04=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KA04']))\n",
    "KA15=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KA15']))\n",
    "KA30=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KA30']))\n",
    "KA16=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KA16']))\n",
    "\n",
    "# #inner Fault\n",
    "KI16=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KI16']))\n",
    "KI17=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KI17']))\n",
    "KI18=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KI18']))\n",
    "KI21=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KI21']))\n",
    "KI14=torch.from_numpy(np.asarray(data_c['C_5120L']['real']['KI14']))\n",
    "\n",
    "# Constructing realing data_c and labels for working conition 0 \n",
    "real_data_c=torch.cat((K001,KA22,KA04,,KA15,KA30,KA16,KI14,KI21,KI17,KI18,KI16),dim=0)\n",
    "# Generating labels\n",
    "a=torch.LongTensor(K001.size(0)).fill_(0)\n",
    "b=torch.LongTensor(KA04.size(0)*5).fill_(1)\n",
    "c=torch.LongTensor(KA04.size(0)*5).fill_(2)\n",
    "real_labels_c=torch.cat((a,b,c),dim=0)\n",
    "print(real_data_c.size())\n",
    "print(real_labels_c.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split  working condition C  into traininhg and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * (real_data_c[0].size(0)))\n",
    "test_size = real_data_c[0].size(0)- train_size\n",
    "inx=np.arange(real_data_c[0].size(0))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(inx, [train_size, test_size])\n",
    "\n",
    "train_data=real_data_c[0][train_dataset]\n",
    "train_labels=real_data_c[1][train_dataset]\n",
    "test_data=real_data_c[0][test_dataset].float()\n",
    "test_labels=real_data_c[1][test_dataset].long()\n",
    "\n",
    "domain_c=train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct data and labels working condition D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting files for realing data_d \n",
    "# health data_d\n",
    "K001=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['K001']))\n",
    "\n",
    "#outer Fault \n",
    "KA22=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KA22']))\n",
    "KA04=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KA04']))\n",
    "KA15=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KA15']))\n",
    "KA30=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KA30']))\n",
    "KA16=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KA16']))\n",
    "\n",
    "# #inner Fault\n",
    "KI16=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KI16']))\n",
    "KI17=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KI17']))\n",
    "KI18=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KI18']))\n",
    "KI21=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KI21']))\n",
    "KI14=torch.from_numpy(np.asarray(data_d['D_5120L']['real']['KI14']))\n",
    "\n",
    "# Constructing realing data_d and labels for working conition 0 \n",
    "real_data_d=torch.cat((K001,KA22,KA04,,KA15,KA30,KA16,KI14,KI21,KI17,KI18,KI16),dim=0)\n",
    "print(real_data_d.size())\n",
    "\n",
    "# Generating labels\n",
    "a=torch.LongTensor(K001.size(0)).fill_(0)\n",
    "b=torch.LongTensor(KA04.size(0)*5).fill_(1)\n",
    "c=torch.LongTensor(KA04.size(0)*5).fill_(2)\n",
    "real_labels_d=torch.cat((a,b,c),dim=0)\n",
    "print(real_labels_d.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split  working condition D  into traininhg and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * (real_data_d[0].size(0)))\n",
    "test_size = real_data_d[0].size(0)- train_size\n",
    "inx=np.arange(real_data_d[0].size(0))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(inx, [train_size, test_size])\n",
    "\n",
    "train_data=real_data_d[0][train_dataset]\n",
    "train_labels=real_data_d[1][train_dataset]\n",
    "test_data=real_data_d[0][test_dataset].float()\n",
    "test_labels=real_data_d[1][test_dataset].long()\n",
    "\n",
    "domain_d=train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the 4 differnet working conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_domains_raw=domain_a,domain_b,domain_c,domain_d\n",
    "torch.save(real_domains_raw,'real_domains_raw.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
