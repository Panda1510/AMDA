{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time \n",
    "from torch.autograd import grad\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "device = torch.device('cuda')\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_AMDA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_AMDA, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # first layer  4096*1-->  1017*8\n",
    "            nn.Conv1d(1, 8, kernel_size=32,stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # second layer  1017*8-->  250*16\n",
    "            nn.Conv1d(8, 16, kernel_size=16,stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # third layer  250*16-->  60*32\n",
    "            nn.Conv1d(16, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), \n",
    "            # fourth layer 60*32--> 14*32\n",
    "            nn.Conv1d(32, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # fifth layer 14*32--> 3*64\n",
    "            nn.Conv1d(32, 64, kernel_size=3,stride=2,padding=1),\n",
    "            nn.MaxPool1d(2))\n",
    "         # flatenning wit fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 256)# optimal when 0 source domain\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv_out = self.encoder(input)\n",
    "        feat = self.fc1(conv_out.view(conv_out.shape[0],-1))\n",
    "        return feat        \n",
    "    \"\"\"classifier model for AMDA.\"\"\"\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(256, 3) #this with 0 as souce it give optimal results \n",
    "  \n",
    "\n",
    "    def forward(self, feat):\n",
    "        out = F.dropout(F.relu(feat), training=self.training)\n",
    "        out = self.fc2(out)\n",
    "        return out  \n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator model for source domain.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, output_dims),\n",
    "            nn.LogSoftmax())\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real KAt Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=torch.load('../data_5120L_new/real_domains_raw.pt')\n",
    "wk_cond_a_full,wk_cond_b_full,wk_cond_c_full,wk_cond_d_full=real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Shift Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting source and target domain \n",
    "source_domain,source_labels,test_data,test_labels=wk_cond_a_full\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_b_full\n",
    "target_domain_1,target_labels_1,target_test_1,target_test_labels_1=wk_cond_c_full\n",
    "target_domain_2,target_labels_2,target_test_2,target_test_labels_2=wk_cond_d_full\n",
    "\n",
    "sample_length=source_domain.size(1)\n",
    "num_samples=source_domain.size(0)\n",
    "num_test_samples=test_data.size(0)\n",
    "num_target_samples= target_test.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Params for AMDA.\"\"\"\n",
    "# params for setting up models\n",
    "d_input_dims = 256\n",
    "d_hidden_dims = 256\n",
    "d_output_dims = 2\n",
    "# params for training network\n",
    "num_epochs_pre = 30 \n",
    "log_step_pre = 5\n",
    "eval_step_pre = 20\n",
    "save_step_pre = 100\n",
    "num_epochs = 5 \n",
    "log_step = 1\n",
    "save_step = 100\n",
    "# params for optimizing models\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "c_init_learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "bs=100 #20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train classifier for source domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "    # set train state for Dropout and BN layers\n",
    "    src_encoder.train()\n",
    "    classifier.train()\n",
    "    # setup criterion and optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=c_init_learning_rate,\n",
    "        betas=(beta1, beta2))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    shuffled_indices=torch.randperm(num_samples)\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "    t0 = time.time()\n",
    "    for epoch in range(num_epochs_pre):\n",
    "        running_loss=0\n",
    "        running_accuracy=0\n",
    "        num_batches=0\n",
    "        shuffled_indices=torch.randperm(num_samples)\n",
    "        for step in range(0,num_samples,bs):\n",
    "            # shuffled data samples\n",
    "            indices=shuffled_indices[step:step+bs]\n",
    "            # training on target domain_a as a source\n",
    "            minibatch_data =  Variable(source_domain[indices].unsqueeze(dim=1))\n",
    "            minibatch_label=  Variable(source_labels[indices].squeeze())\n",
    "            minibatch_data=minibatch_data.to(device)\n",
    "            minibatch_label=minibatch_label.to(device)\n",
    "    \n",
    "            # zero gradients for optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute loss for critic\n",
    "            preds =classifier (encoder(minibatch_data.float()))\n",
    "            loss = criterion(preds, minibatch_label)\n",
    "            \n",
    "            # optimize source classifier\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().item()\n",
    "        \n",
    "            running_accuracy += (preds.max(1)[1] == minibatch_label).float().mean().item()\n",
    "            num_batches+=1\n",
    "        # print epoch info\n",
    "        if ((epoch) % log_step_pre == 0):\n",
    "            print(\"Epoch [{}/{}] : loss={} train_accuracy={}\"\n",
    "                  .format(epoch,\n",
    "                          num_epochs_pre,\n",
    "                          running_loss/num_batches,\n",
    "                        running_accuracy*100/num_batches ))\n",
    "       \n",
    "        print('{} seconds'.format(time.time() - t0))\n",
    "        # eval model on test set\n",
    "        if ((epoch + 1) % eval_step_pre == 0):\n",
    "            eval_src(encoder, classifier)\n",
    "    return encoder, classifier\n",
    "\n",
    "\n",
    "def eval_src(encoder, classifier):\n",
    "    \"\"\"Evaluate classifier for source domain.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    num_batches=0\n",
    "    mean_loss=0\n",
    "    run_loss=0\n",
    "    # set loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    shuffled_indices=torch.randperm(num_test_samples) #[0:4000]\n",
    "\n",
    "#     bs=20\n",
    "    for i in range(0,num_test_samples,bs):\n",
    "        indices=shuffled_indices[i:i+bs]\n",
    "        minibatch_data =  test_data[indices].unsqueeze(dim=1)\n",
    "        minibatch_label= test_labels[indices].squeeze()\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        scores=classifier(encoder(minibatch_data.float()))\n",
    "        # calculate accuracy                      \n",
    "        acc += (scores.max(1)[1] == minibatch_label).float().mean().item()\n",
    "        x.append(scores.max(1)[1])\n",
    "        y.append(minibatch_label)\n",
    "        loss = criterion(scores, minibatch_label)\n",
    "        num_batches+=1\n",
    "        run_loss += loss.detach().item()\n",
    "    mean_accuracy = acc / num_batches\n",
    "    mean_loss = run_loss / num_batches\n",
    "    \n",
    "    print(\"Avg Loss = {}, Avg Accuracy = {}\".format( mean_loss, mean_accuracy*100))\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation Fucntion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tgt(src_encoder, tgt_encoder, critic):\n",
    "    \"\"\"Train encoder for target domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "    # set train state for Dropout and BN layers\n",
    "    tgt_encoder.train()\n",
    "    critic.train()\n",
    "    # setup criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_tgt = optim.Adam(tgt_encoder.parameters(),\n",
    "                               lr=c_learning_rate,\n",
    "                               betas=(beta1, beta2))\n",
    "    optimizer_critic = optim.Adam(critic.parameters(),\n",
    "                                  lr=d_learning_rate,\n",
    "                                  betas=(beta1, beta2))\n",
    "    len_data_loader =num_samples\n",
    "    t1 = time.time()\n",
    "\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "    for epoch in range(num_epochs):\n",
    "        # initilize loss\n",
    "        run_critic_loss=0\n",
    "        acc=0\n",
    "        run_tgt_loss=0\n",
    "        num_batches=0\n",
    "        shuffled_indices=torch.randperm(num_samples)#[0:4000]\n",
    "        # zip source and target data pair\n",
    "        for i in range(0,num_samples,bs):\n",
    "            ###########################\n",
    "            # 2.1 train discriminator #\n",
    "            ###########################\n",
    "            indices=shuffled_indices[i:i+bs]\n",
    "            # make  variable\n",
    "            sample_src= Variable(source_domain[indices].float().unsqueeze(dim=1)).to(device)\n",
    "            sample_tgt_1=Variable(target_domain[indices].float().unsqueeze(dim=1)).to(device)\n",
    "            sample_tgt_2=Variable(target_domain_1[i:i+bs].float().unsqueeze(dim=1)).to(device)\n",
    "            sample_tgt_3=Variable(target_domain_2[i:i+bs].float().unsqueeze(dim=1)).to(device)\n",
    "\n",
    "            # zero gradients for optimizer\n",
    "            optimizer_critic.zero_grad()\n",
    "\n",
    "            # extract and concat features\n",
    "            feat_src = src_encoder(sample_src)\n",
    "            feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "            feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "            feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "            feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "            feat_concat = torch.cat((feat_src, feat_tgt), 0)\n",
    "    \n",
    "            # predict on discriminator\n",
    "            pred_concat = critic(feat_concat.detach()).to(device)\n",
    "            # prepare real and fake lafeat_tgt_1bel\n",
    "            label_src =Variable(torch.ones(feat_src.size(0)).long())\n",
    "            label_tgt = Variable(torch.zeros(feat_tgt.size(0)).long())\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0).to(device)\n",
    "\n",
    "            # compute loss for critic\n",
    "            loss_critic = criterion(pred_concat, label_concat)\n",
    "            loss_critic.backward()\n",
    "\n",
    "            # optimize critic\n",
    "            optimizer_critic.step()\n",
    "\n",
    "            pred_cls = torch.squeeze(pred_concat.max(1)[1])\n",
    "            acc += (pred_cls == label_concat).float().mean()\n",
    "            run_critic_loss+=  loss_critic.detach().item()\n",
    "            \n",
    "            ############################\n",
    "            # 2.2 train target encoder #\n",
    "            ############################\n",
    "            optimizer_tgt.zero_grad() # edited here becareful \n",
    "            for i in range (1):\n",
    "            # zero gradients for optimizer\n",
    "                # extract and target features\n",
    "                feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "                feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "                feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "#                 feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2),0)\n",
    "                feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "\n",
    "                # predict on discriminator\n",
    "                pred_tgt = critic(feat_tgt).to(device)\n",
    "\n",
    "                # prepare fake labels to enforce the feature extractor to confuse the critic \n",
    "                label_tgt = Variable(torch.ones(feat_tgt.size(0)).long()).to(device)\n",
    "\n",
    "                # compute loss for target encoder\n",
    "                loss_tgt = criterion(pred_tgt, label_tgt)\n",
    "                loss_tgt.backward()\n",
    "\n",
    "                # optimize target encoder\n",
    "                optimizer_tgt.step()\n",
    "\n",
    "                run_tgt_loss+=loss_tgt.detach().item()\n",
    "            num_batches+=1\n",
    "            \n",
    "        #######################\n",
    "        # 2.3 print epoch info #\n",
    "        #######################\n",
    "        print('{} seconds'.format(time.time() - t1))\n",
    "        if ((epoch) % log_step == 0):\n",
    "            print(\"Epoch [{}/{}] :\"\n",
    "                  \"discriminator_loss={:.5f} target_loss={:.5f} discriminator_acc={:.5f}\"\n",
    "                  .format(epoch,\n",
    "                         num_epochs,\n",
    "                          run_critic_loss/num_batches,\n",
    "                          run_tgt_loss/(num_batches*5),\n",
    "                          acc.data[0]/num_batches))\n",
    "            print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "            print(\">>> source only <<<\")\n",
    "            eval_tgt(src_encoder, src_classifier)\n",
    "            print(\">>> domain adaption <<<\")\n",
    "            eval_tgt(tgt_encoder, src_classifier)\n",
    "    return tgt_encoder\n",
    "\n",
    "def eval_tgt(encoder, classifier):\n",
    "    \"\"\"Evaluation for target encoder by source classifier on target dataset.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    mean_loss=0\n",
    "    mean_acc=0\n",
    "    num_batches=0\n",
    "    # set loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    shuffled_indices_T=torch.randperm(num_target_samples)\n",
    "    # evaluate network\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,num_target_samples,bs):\n",
    "            indices_T=shuffled_indices_T[i:i+bs]\n",
    "            minibatch_data =  target_test[indices_T].unsqueeze(dim=1)\n",
    "            minibatch_label= target_test_labels[indices_T].squeeze()\n",
    "            minibatch_data=minibatch_data.to(device)\n",
    "            minibatch_label=minibatch_label.to(device)\n",
    "            scores=classifier(encoder(minibatch_data))\n",
    "            # calculate accuracy                     \n",
    "            acc += (scores.max(1)[1] == minibatch_label).float().mean().item()\n",
    "            loss += criterion(scores, minibatch_label)\n",
    "            x.append(scores.max(1)[1])\n",
    "            y.append(minibatch_label)\n",
    "            num_batches+=1\n",
    "    mean_accuracy = acc / num_batches\n",
    "    mean_loss = loss / num_batches\n",
    "    print(\"Avg Accuracy = {:2%}\".format(mean_accuracy))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Main Code  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] : loss=1.6868433492879074 train_accuracy=45.362846087664366\n",
      "1.1918480396270752 seconds\n",
      "2.310789108276367 seconds\n",
      "3.4039793014526367 seconds\n",
      "4.45129132270813 seconds\n",
      "5.5062174797058105 seconds\n",
      "Epoch [5/50] : loss=0.2215828502861162 train_accuracy=91.22829648355643\n",
      "6.593669414520264 seconds\n",
      "7.643713474273682 seconds\n",
      "8.696155548095703 seconds\n",
      "9.748639583587646 seconds\n",
      "10.799995183944702 seconds\n",
      "Epoch [10/50] : loss=0.006018737720296485 train_accuracy=99.84374927977721\n",
      "11.857589960098267 seconds\n",
      "12.909178018569946 seconds\n",
      "13.962198495864868 seconds\n",
      "15.02686619758606 seconds\n",
      "16.080912351608276 seconds\n",
      "Epoch [15/50] : loss=0.0010680420701968767 train_accuracy=99.97916656235854\n",
      "17.131296634674072 seconds\n",
      "18.20425057411194 seconds\n",
      "19.25678515434265 seconds\n",
      "20.310431718826294 seconds\n",
      "21.36260151863098 seconds\n",
      "Avg Loss = 1.1473339294220417e-05, Avg Accuracy = 100.0\n",
      "Epoch [20/50] : loss=0.00014957914743263245 train_accuracy=100.0\n",
      "22.609604835510254 seconds\n"
     ]
    }
   ],
   "source": [
    "# # load models\n",
    "src_encoder = Encoder_AMDA().to(device)\n",
    "\n",
    "src_classifier= Classifier().to(device)\n",
    "\n",
    "tgt_encoder = Encoder_AMDA().to(device)\n",
    "\n",
    "critic = Discriminator(input_dims=d_input_dims,\n",
    "                                  hidden_dims=d_hidden_dims,\n",
    "                                  output_dims=d_output_dims).to(device)\n",
    "src_encoder, src_classifier = train_src(\n",
    "        src_encoder, src_classifier)\n",
    "# src_encoder.load_state_dict(torch.load('src_enc_wk_d_temp.pt'))\n",
    "# src_classifier.load_state_dict(torch.load('classifier_wk_d_temp.pt'))\n",
    "\n",
    "tgt_encoder.load_state_dict(src_encoder.state_dict())\n",
    "tgt_encoder = train_tgt(src_encoder, tgt_encoder, critic)\n",
    "\n",
    "# eval target encoder on test set of target dataset\n",
    "print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "print(\">>> source only <<<\")\n",
    "eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "eval_tgt(tgt_encoder, src_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Mutiple Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> domain adaption_B <<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 81.833508%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 98.308587%\n",
      ">>> domain adaption _C<<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 85.876986%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 96.997876%\n",
      ">>> domain adaption _D<<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 86.635205%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 100.000000%\n"
     ]
    }
   ],
   "source": [
    "src_encoder.load_state_dict(torch.load('src_enc_wk_b_M_ADDA_new.pt'))\n",
    "src_classifier.load_state_dict(torch.load('classifier_wk_b_M_ADDA_mew.pt'))\n",
    "tgt_encoder.load_state_dict(torch.load('tgt_enc_wk_b_M_ADDA_new.pt'))\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_b_full\n",
    "\n",
    "print(\">>> domain adaption_B <<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_c_full\n",
    "print(\">>> domain adaption _C<<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_d_full\n",
    "print(\">>> domain adaption _D<<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
