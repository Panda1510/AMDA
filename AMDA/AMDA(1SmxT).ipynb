{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time \n",
    "from torch.autograd import grad\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "device = torch.device('cuda')\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_AMDA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_AMDA, self).__init__()\n",
    "#         self.restored = False\n",
    "        self.encoder = nn.Sequential(\n",
    "            # first layer  4096*1-->  1017*8\n",
    "            nn.Conv1d(1, 8, kernel_size=32,stride=2, padding=1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # second layer  1017*8-->  250*16\n",
    "            nn.Conv1d(8, 16, kernel_size=16,stride=2, padding=1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # third layer  250*16-->  60*32\n",
    "            nn.Conv1d(16, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), \n",
    "            # fourth layer 60*32--> 14*32\n",
    "            nn.Conv1d(32, 32, kernel_size=8,stride=2,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            # fifth layer 14*32--> 3*64\n",
    "            nn.Conv1d(32, 64, kernel_size=3,stride=2,padding=1),\n",
    "#             nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "         # flatenning wit fully connected layers\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 256)# optimal when 0 source domain\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv_out = self.encoder(input)\n",
    "#         conv_out=F.dropout(conv_out)# we didn't need it when source domain is zero condition\n",
    "        feat = self.fc1(conv_out.view(conv_out.shape[0],-1))\n",
    "        return feat\n",
    "            \n",
    "    \"\"\"classifier model for AMDA.\"\"\"\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(256, 10) #this with 0 as souce it give optimal results \n",
    "  \n",
    "\n",
    "    def forward(self, feat):\n",
    "        out = F.dropout(F.relu(feat), training=self.training)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator model for source domain.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "#         self.restored = False\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims, output_dims),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        out = self.layer(input)\n",
    "        return out\n",
    "\n",
    "\n",
    "src_ecoder=Encoder_AMDA().to(device)\n",
    "tgt_encoder=Encoder_AMDA().to(device)\n",
    "classifier= Classifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Loading \n",
    "# wk_cond_a_full=torch.load('../data_5120L_new/wk_cond_a_full.pt')\n",
    "# wk_cond_b_full=torch.load('../data_5120L_new/wk_cond_b_full.pt')\n",
    "# wk_cond_c_full=torch.load('../data_5120L_new/wk_cond_c_full.pt')\n",
    "# wk_cond_d_full=torch.load('../data_5120L_new/wk_cond_d_full.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifcial=torch.load('../data_5120L_new/artificial_domains_raw')\n",
    "# wk_cond_a_full,wk_cond_b_full,wk_cond_c_full,wk_cond_d_full=artifcial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=torch.load('../data_5120L_new/real_domains_raw.pt')\n",
    "wk_cond_a_full,wk_cond_b_full,wk_cond_c_full,wk_cond_d_full=real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Shift Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #selecting source and target domain \n",
    "# source_domain,source_labels,test_data,test_labels=wk_cond_a_full\n",
    "# target_domain,target_labels,target_test,target_test_labels=wk_cond_b_full\n",
    "# target_domain_1,target_labels_1,target_test_1,target_test_labels_1=wk_cond_c_full\n",
    "# target_domain_2,target_labels_2,target_test_2,target_test_labels_2=wk_cond_d_full\n",
    "\n",
    "# sample_length=source_domain.size(1)\n",
    "# num_samples=source_domain.size(0)\n",
    "# num_test_samples=test_data.size(0)\n",
    "# num_target_samples= target_test.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Params for ADDA.\"\"\"\n",
    "\n",
    "# params for setting up models\n",
    "model_root = \"pytorch-adda\"\n",
    "d_input_dims = 256\n",
    "d_hidden_dims = 256\n",
    "d_output_dims = 2\n",
    "\n",
    "# params for training network\n",
    "num_epochs_pre = 30 # wK_a= 50; wk_B=100\n",
    "log_step_pre = 5\n",
    "eval_step_pre = 20\n",
    "save_step_pre = 100\n",
    "num_epochs = 5 # wk_a=20 \n",
    "log_step = 1\n",
    "save_step = 100\n",
    "manual_seed = None\n",
    "\n",
    "# params for optimizing models\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "c_init_learning_rate = 1e-4\n",
    "\n",
    "\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "bs=100 #20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_src(encoder, classifier):\n",
    "    \"\"\"Train classifier for source domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "    # set train state for Dropout and BN layers\n",
    "    src_encoder.train()\n",
    "    classifier.train()\n",
    "\n",
    "    # setup criterion and optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        list(encoder.parameters()) + list(classifier.parameters()),\n",
    "        lr=c_init_learning_rate,\n",
    "        betas=(beta1, beta2))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    shuffled_indices=torch.randperm(num_samples)\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs_pre):\n",
    "        running_loss=0\n",
    "        running_accuracy=0\n",
    "        num_batches=0\n",
    "        shuffled_indices=torch.randperm(num_samples)\n",
    "\n",
    "        for step in range(0,num_samples,bs):\n",
    "            \n",
    "            # shuffled data samples\n",
    "            indices=shuffled_indices[step:step+bs]\n",
    "            # training on target domain_a as a source\n",
    "            minibatch_data =  Variable(source_domain[indices].unsqueeze(dim=1))\n",
    "            minibatch_label=  Variable(source_labels[indices].squeeze())\n",
    "            minibatch_data=minibatch_data.to(device)\n",
    "            minibatch_label=minibatch_label.to(device)\n",
    "#             inputs = (minibatch_data - src_mean)/src_std  \n",
    "#             inputs=inputs.to(device)\n",
    "    \n",
    "            # zero gradients for optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute loss for critic\n",
    "            preds =classifier (encoder(minibatch_data.float()))\n",
    "            loss = criterion(preds, minibatch_label)\n",
    "            \n",
    "            # optimize source classifier\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().item()\n",
    "        \n",
    "            running_accuracy += (preds.max(1)[1] == minibatch_label).float().mean().item()\n",
    "            num_batches+=1\n",
    "        # print epoch info\n",
    "        if ((epoch) % log_step_pre == 0):\n",
    "            print(\"Epoch [{}/{}] : loss={} train_accuracy={}\"\n",
    "                  .format(epoch,\n",
    "                          num_epochs_pre,\n",
    "                          running_loss/num_batches,\n",
    "                        running_accuracy*100/num_batches ))\n",
    "       \n",
    "        print('{} seconds'.format(time.time() - t0))\n",
    "        # eval model on test set\n",
    "        if ((epoch + 1) % eval_step_pre == 0):\n",
    "            eval_src(encoder, classifier)\n",
    "    return encoder, classifier\n",
    "\n",
    "\n",
    "def eval_src(encoder, classifier):\n",
    "    \"\"\"Evaluate classifier for source domain.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    num_batches=0\n",
    "    mean_loss=0\n",
    "    run_loss=0\n",
    "    # set loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    # generate random vector of size 4000 to fit the gpu\n",
    "#     shuffled_indices=torch.randperm(num_test_samples) #[0:4000]\n",
    "    shuffled_indices=torch.randperm(num_test_samples) #[0:4000]\n",
    "\n",
    "#     bs=20\n",
    "    for i in range(0,num_test_samples,bs):\n",
    "        indices=shuffled_indices[i:i+bs]\n",
    "        minibatch_data =  test_data[indices].unsqueeze(dim=1)\n",
    "        minibatch_label= test_labels[indices].squeeze()\n",
    "#         print(minibatch_data.size())\n",
    "#         print(minibatch_label.size())\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "#         inputs = (minibatch_data - src_mean)/src_std  \n",
    "#         inputs=inputs.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        scores=classifier(encoder(minibatch_data.float()))\n",
    "        # calculate accuracy\n",
    "                               \n",
    "        acc += (scores.max(1)[1] == minibatch_label).float().mean().item()\n",
    "\n",
    "        x.append(scores.max(1)[1])\n",
    "        y.append(minibatch_label)\n",
    "        loss = criterion(scores, minibatch_label)\n",
    "        num_batches+=1\n",
    "        run_loss += loss.detach().item()\n",
    "#      \n",
    "    mean_accuracy = acc / num_batches\n",
    "#     acc_plt.append(mean_accuracy)\n",
    "    mean_loss = run_loss / num_batches\n",
    "    \n",
    "    print(\"Avg Loss = {}, Avg Accuracy = {}\".format( mean_loss, mean_accuracy*100))\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation Fucntion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tgt(src_encoder, tgt_encoder, critic):\n",
    "    \"\"\"Train encoder for target domain.\"\"\"\n",
    "    ####################\n",
    "    # 1. setup network #\n",
    "    ####################\n",
    "    # set train state for Dropout and BN layers\n",
    "    tgt_encoder.train()\n",
    "    critic.train()\n",
    "    # setup criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_tgt = optim.Adam(tgt_encoder.parameters(),\n",
    "                               lr=c_learning_rate,\n",
    "                               betas=(beta1, beta2))\n",
    "    optimizer_critic = optim.Adam(critic.parameters(),\n",
    "                                  lr=d_learning_rate,\n",
    "                                  betas=(beta1, beta2))\n",
    "    len_data_loader =num_samples\n",
    "    t1 = time.time()\n",
    "\n",
    "    ####################\n",
    "    # 2. train network #\n",
    "    ####################\n",
    "    for epoch in range(num_epochs):\n",
    "        # initilize loss\n",
    "        run_critic_loss=0\n",
    "        acc=0\n",
    "        run_tgt_loss=0\n",
    "        num_batches=0\n",
    "        shuffled_indices=torch.randperm(num_samples)#[0:4000]\n",
    "        # zip source and target data pair\n",
    "        for i in range(0,num_samples,bs):\n",
    "            ###########################\n",
    "            # 2.1 train discriminator #\n",
    "            ###########################\n",
    "            indices=shuffled_indices[i:i+bs]\n",
    "#             indices_T=shuffled_indices_T[i:i+bs]\n",
    "            # make  variable\n",
    "            sample_src= Variable(source_domain[indices].float().unsqueeze(dim=1)).to(device)\n",
    "            sample_tgt_1=Variable(target_domain[indices].float().unsqueeze(dim=1)).to(device)\n",
    "#             sample_tgt_2=Variable(target_domain_1[i:i+bs].float().unsqueeze(dim=1)).to(device)\n",
    "#             sample_tgt_3=Variable(target_domain_2[i:i+bs].float().unsqueeze(dim=1)).to(device)\n",
    "\n",
    "            # zero gradients for optimizer\n",
    "            optimizer_critic.zero_grad()\n",
    "\n",
    "            # extract and concat features\n",
    "            feat_src = src_encoder(sample_src)\n",
    "            feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "#             feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "#             feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "#             feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2),0)\n",
    "#             feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "            feat_concat = torch.cat((feat_src, feat_tgt_1), 0)\n",
    "    \n",
    "            # predict on discriminator\n",
    "            pred_concat = critic(feat_concat.detach()).to(device)\n",
    "            # prepare real and fake lafeat_tgt_1bel\n",
    "            label_src =Variable(torch.ones(feat_src.size(0)).long())\n",
    "            label_tgt = Variable(torch.zeros(feat_tgt_1.size(0)).long())\n",
    "            label_concat = torch.cat((label_src, label_tgt), 0).to(device)\n",
    "\n",
    "            # compute loss for critic\n",
    "#             print(pred_concat.size(), label_concat.size())\n",
    "            loss_critic = criterion(pred_concat, label_concat)\n",
    "            loss_critic.backward()\n",
    "\n",
    "            # optimize critic\n",
    "            optimizer_critic.step()\n",
    "\n",
    "            pred_cls = torch.squeeze(pred_concat.max(1)[1])\n",
    "            acc += (pred_cls == label_concat).float().mean()\n",
    "            run_critic_loss+=  loss_critic.detach().item()\n",
    "            \n",
    "            ############################\n",
    "            # 2.2 train target encoder #\n",
    "            ############################\n",
    "            optimizer_tgt.zero_grad() # edited here becareful \n",
    "            for i in range (1):\n",
    "            # zero gradients for optimizer\n",
    "#                 optimizer_critic.zero_grad()\n",
    "                # extract and target features\n",
    "                feat_tgt_1 = tgt_encoder(sample_tgt_1)\n",
    "#                 feat_tgt_2 = tgt_encoder(sample_tgt_2)\n",
    "#                 feat_tgt_3 = tgt_encoder(sample_tgt_3)\n",
    "#                 feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2),0)\n",
    "#                 feat_tgt= torch.cat((feat_tgt_1,feat_tgt_2,feat_tgt_3),0)\n",
    "\n",
    "                # predict on discriminator\n",
    "                pred_tgt = critic(feat_tgt_1).to(device)\n",
    "\n",
    "                # prepare fake labels to enforce the feature extractor to confuse the critic \n",
    "                label_tgt = Variable(torch.ones(feat_tgt_1.size(0)).long()).to(device)\n",
    "\n",
    "                # compute loss for target encoder\n",
    "                loss_tgt = criterion(pred_tgt, label_tgt)\n",
    "                loss_tgt.backward()\n",
    "\n",
    "                # optimize target encoder\n",
    "                optimizer_tgt.step()\n",
    "\n",
    "                run_tgt_loss+=loss_tgt.detach().item()\n",
    "            num_batches+=1\n",
    "            \n",
    "        #######################\n",
    "        # 2.3 print epoch info #\n",
    "        #######################\n",
    "        print('{} seconds'.format(time.time() - t1))\n",
    "        if ((epoch) % log_step == 0):\n",
    "            print(\"Epoch [{}/{}] :\"\n",
    "                  \"discriminator_loss={:.5f} target_loss={:.5f} discriminator_acc={:.5f}\"\n",
    "                  .format(epoch,\n",
    "                         num_epochs,\n",
    "                          run_critic_loss/num_batches,\n",
    "                          run_tgt_loss/(num_batches*5),\n",
    "                          acc.data[0]/num_batches))\n",
    "            print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "            print(\">>> source only <<<\")\n",
    "            eval_tgt(src_encoder, src_classifier)\n",
    "            print(\">>> domain adaption <<<\")\n",
    "            eval_tgt(tgt_encoder, src_classifier)\n",
    "    return tgt_encoder\n",
    "\n",
    "def eval_tgt(encoder, classifier):\n",
    "    \"\"\"Evaluation for target encoder by source classifier on target dataset.\"\"\"\n",
    "    # set eval state for Dropout and BN layers\n",
    "    encoder.eval()\n",
    "    classifier.eval()\n",
    "    # init loss and accuracy\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    mean_loss=0\n",
    "    mean_acc=0\n",
    "    num_batches=0\n",
    "    # set loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    shuffled_indices_T=torch.randperm(num_target_samples)\n",
    "    # evaluate network\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,num_target_samples,bs):\n",
    "            indices_T=shuffled_indices_T[i:i+bs]\n",
    "            minibatch_data =  target_test[indices_T].unsqueeze(dim=1)\n",
    "            minibatch_label= target_test_labels[indices_T].squeeze()\n",
    "            minibatch_data=minibatch_data.to(device)\n",
    "            minibatch_label=minibatch_label.to(device)\n",
    "            scores=classifier(encoder(minibatch_data))\n",
    "            # calculate accuracy                     \n",
    "            acc += (scores.max(1)[1] == minibatch_label).float().mean().item()\n",
    "            loss += criterion(scores, minibatch_label)\n",
    "            x.append(scores.max(1)[1])\n",
    "            y.append(minibatch_label)\n",
    "            num_batches+=1\n",
    "    mean_accuracy = acc / num_batches\n",
    "    mean_loss = loss / num_batches\n",
    "    print(\"Avg Accuracy = {:2%}\".format(mean_accuracy))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Main Code  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1SmxT data arrangement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] : loss=1.7770315327992041 train_accuracy=43.56249879735211\n",
      "1.0468721389770508 seconds\n",
      "2.0926475524902344 seconds\n",
      "3.1392269134521484 seconds\n",
      "4.221972942352295 seconds\n",
      "5.2716758251190186 seconds\n",
      "Epoch [5/50] : loss=0.30751354604338604 train_accuracy=90.25781092544396\n",
      "6.347921371459961 seconds\n",
      "7.395268678665161 seconds\n",
      "8.44494891166687 seconds\n",
      "9.494156837463379 seconds\n",
      "10.545499801635742 seconds\n",
      "Epoch [10/50] : loss=0.0043145120750220185 train_accuracy=99.92708303034306\n",
      "11.629141330718994 seconds\n",
      "12.698097467422485 seconds\n",
      "13.743008852005005 seconds\n",
      "14.792064905166626 seconds\n",
      "15.83873462677002 seconds\n",
      "Epoch [15/50] : loss=0.0007617305550411402 train_accuracy=99.97916656235854\n",
      "16.887821912765503 seconds\n",
      "17.9360454082489 seconds\n",
      "18.984768867492676 seconds\n",
      "20.033238649368286 seconds\n",
      "21.08421301841736 seconds\n",
      "Avg Loss = 3.0695519349248526e-05, Avg Accuracy = 100.0\n",
      "Epoch [20/50] : loss=6.945494220052713e-05 train_accuracy=100.0\n",
      "22.319313287734985 seconds\n",
      "23.366045713424683 seconds\n",
      "24.40956711769104 seconds\n",
      "25.453290700912476 seconds\n",
      "26.49650263786316 seconds\n",
      "Epoch [25/50] : loss=8.37466777966108e-06 train_accuracy=100.0\n",
      "27.539888620376587 seconds\n",
      "28.585572242736816 seconds\n",
      "29.633505821228027 seconds\n",
      "30.674448251724243 seconds\n",
      "31.718937873840332 seconds\n",
      "Epoch [30/50] : loss=7.017619050864177e-07 train_accuracy=100.0\n",
      "32.759153604507446 seconds\n",
      "33.799978494644165 seconds\n",
      "34.843913078308105 seconds\n",
      "35.88790202140808 seconds\n",
      "36.930694818496704 seconds\n",
      "Epoch [35/50] : loss=9.208917598850046e-08 train_accuracy=100.0\n",
      "37.974226236343384 seconds\n",
      "39.01498293876648 seconds\n",
      "40.06036019325256 seconds\n",
      "41.10391807556152 seconds\n",
      "42.151381969451904 seconds\n",
      "Avg Loss = 1.595659961451918e-07, Avg Accuracy = 100.0\n",
      "Epoch [40/50] : loss=2.615503851068531e-05 train_accuracy=100.0\n",
      "43.375725746154785 seconds\n",
      "44.41943693161011 seconds\n",
      "45.46253776550293 seconds\n",
      "46.51937484741211 seconds\n",
      "47.570640325546265 seconds\n",
      "Epoch [45/50] : loss=9.745359317673656e-08 train_accuracy=100.0\n",
      "48.614052295684814 seconds\n",
      "49.65441584587097 seconds\n",
      "50.699283599853516 seconds\n",
      "51.74470615386963 seconds\n",
      "52.78914833068848 seconds\n",
      "5.762599229812622 seconds\n",
      "Epoch [0/40] :discriminator_loss=0.70324 target_loss=0.14427 discriminator_acc=0.49699\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedragab1992/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:115: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy = 92.615745%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.562258%\n",
      "12.579899072647095 seconds\n",
      "Epoch [1/40] :discriminator_loss=0.68659 target_loss=0.14779 discriminator_acc=0.55101\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.602908%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.588787%\n",
      "19.41005802154541 seconds\n",
      "Epoch [2/40] :discriminator_loss=0.68975 target_loss=0.14735 discriminator_acc=0.53619\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.608043%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.350448%\n",
      "26.42245888710022 seconds\n",
      "Epoch [3/40] :discriminator_loss=0.69063 target_loss=0.14768 discriminator_acc=0.53296\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.618312%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.263584%\n",
      "33.21459412574768 seconds\n",
      "Epoch [4/40] :discriminator_loss=0.69130 target_loss=0.14707 discriminator_acc=0.52879\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.618312%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.304235%\n",
      "40.11770558357239 seconds\n",
      "Epoch [5/40] :discriminator_loss=0.69189 target_loss=0.14667 discriminator_acc=0.53163\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.610610%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.279844%\n",
      "47.294119358062744 seconds\n",
      "Epoch [6/40] :discriminator_loss=0.69057 target_loss=0.14668 discriminator_acc=0.53468\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.613178%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.214376%\n",
      "54.13057899475098 seconds\n",
      "Epoch [7/40] :discriminator_loss=0.68950 target_loss=0.14669 discriminator_acc=0.53632\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.610610%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.144200%\n",
      "61.104002237319946 seconds\n",
      "Epoch [8/40] :discriminator_loss=0.68855 target_loss=0.14698 discriminator_acc=0.53554\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.613178%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.201111%\n",
      "68.04968190193176 seconds\n",
      "Epoch [9/40] :discriminator_loss=0.68917 target_loss=0.14707 discriminator_acc=0.53223\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.610610%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.136498%\n",
      "75.35945796966553 seconds\n",
      "Epoch [10/40] :discriminator_loss=0.68580 target_loss=0.14854 discriminator_acc=0.54075\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.620880%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.203678%\n",
      "82.37289309501648 seconds\n",
      "Epoch [11/40] :discriminator_loss=0.68590 target_loss=0.14825 discriminator_acc=0.53911\n",
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 92.608043%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 92.185278%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-679e84b0ef30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtgt_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtgt_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# eval target encoder on test set of target dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-da5460808c80>\u001b[0m in \u001b[0;36mtrain_tgt\u001b[0;34m(src_encoder, tgt_encoder, critic)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0moptimizer_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mrun_tgt_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss_tgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mnum_batches\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#selecting source and target domain \n",
    "source_domain,source_labels,test_data,test_labels=wk_cond_d_full\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_a_full\n",
    "target_domain_1,target_labels_1,target_test_1,target_test_labels_1=wk_cond_b_full\n",
    "target_domain_2,target_labels_2,target_test_2,target_test_labels_2=wk_cond_c_full\n",
    "\n",
    "source_domain=torch.cat((source_domain,source_domain,source_domain),dim=0)\n",
    "source_labels=torch.cat((source_labels,source_labels,source_labels),dim=0)\n",
    "target_domain=torch.cat((target_domain,target_domain_1,target_domain_2),dim=0)\n",
    "target_test=torch.cat((target_test,target_test_1,target_test_2),dim=0)\n",
    "target_test_labels=torch.cat((target_test_labels,target_test_labels_1,target_test_labels_2))\n",
    "sample_length=source_domain.size(1)\n",
    "num_samples=source_domain.size(0)\n",
    "num_test_samples=test_data.size(0)\n",
    "num_target_samples= target_test.size(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_pre = 50 # wK_a= 50; wk_B=100\n",
    "num_epochs = 40 # wk_a=20\n",
    "\n",
    "# # load models\n",
    "src_encoder = Encoder_ADDA().to(device)\n",
    "\n",
    "src_classifier= Classifier().to(device)\n",
    "\n",
    "tgt_encoder = Encoder_ADDA().to(device)\n",
    "\n",
    "critic = Discriminator(input_dims=d_input_dims,\n",
    "                                  hidden_dims=d_hidden_dims,\n",
    "                                  output_dims=d_output_dims).to(device)\n",
    "\n",
    "source_domain,source_labels,test_data,test_labels=wk_cond_b_full\n",
    "num_samples=source_domain.size(0)\n",
    "\n",
    "# # train source model\n",
    "src_encoder, src_classifier = train_src(\n",
    "        src_encoder, src_classifier)\n",
    "# src_encoder.load_state_dict(torch.load('src_enc_wk_d_temp.pt'))\n",
    "# src_classifier.load_state_dict(torch.load('classifier_wk_d_temp.pt'))\n",
    "source_domain=torch.cat((source_domain,source_domain,source_domain),dim=0)\n",
    "num_samples=source_domain.size(0)\n",
    "\n",
    "tgt_encoder.load_state_dict(src_encoder.state_dict())\n",
    "tgt_encoder = train_tgt(src_encoder, tgt_encoder, critic)\n",
    "\n",
    "# eval target encoder on test set of target dataset\n",
    "print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "print(\">>> source only <<<\")\n",
    "eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "eval_tgt(tgt_encoder, src_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> domain adaption_B <<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 57.138918%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 77.898196%\n",
      ">>> domain adaption _C<<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 90.216329%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 99.020146%\n",
      ">>> domain adaption _D<<<\n",
      ">>> source only <<<\n",
      "Avg Accuracy = 99.975610%\n",
      ">>> domain adaption <<<\n",
      "Avg Accuracy = 100.000000%\n"
     ]
    }
   ],
   "source": [
    "# src_encoder.load_state_dict(torch.load('src_enc_wk_b_M_ADDA_new.pt'))\n",
    "# src_classifier.load_state_dict(torch.load('classifier_wk_b_M_ADDA_mew.pt'))\n",
    "# tgt_encoder.load_state_dict(torch.load('tgt_enc_wk_b_M_ADDA_new.pt'))\n",
    "# # critic.load_state_dict(torch.load('critic_wk_b_M_ADDA_new.pt'))\n",
    "num_samples=target_domain_1.size(0)\n",
    "num_target_samples=target_test_1.size(0)\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_a_full\n",
    "\n",
    "print(\">>> domain adaption_B <<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_c_full\n",
    "print(\">>> domain adaption _C<<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n",
    "\n",
    "target_domain,target_labels,target_test,target_test_labels=wk_cond_d_full\n",
    "print(\">>> domain adaption _D<<<\")\n",
    "print(\">>> source only <<<\")\n",
    "x,y=eval_tgt(src_encoder, src_classifier)\n",
    "print(\">>> domain adaption <<<\")\n",
    "x,y=eval_tgt(tgt_encoder, src_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(tgt_encoder.state_dict(), 'tgt_enc_wk_d_artift.pt') \n",
    "# torch.save(critic.state_dict(), 'critic_wk_d_M_artif.pt') \n",
    "# torch.save(src_classifier.state_dict(), 'classifier_wk_d_atif.pt') \n",
    "# torch.save(src_encoder.state_dict(), 'src_enc_wk_d_artif.pt') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
